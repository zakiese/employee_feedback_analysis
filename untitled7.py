# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jYCSY1kmlXa4zMemhTGm8Qsd8-qEmgZq
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('employee_feedback.csv')
df.head()

df.info()

df.describe()

df.isnull().sum()

plt.figure(figsize=(8,4))
sns.countplot(data=df, x='department', order=df['department'].value_counts().index)
plt.title("Employee Count per Department")
plt.xticks(rotation=45)
plt.show()

plt.figure(figsize=(10,5))
sns.countplot(data=df, y='job_role', order=df['job_role'].value_counts().index)
plt.title("Employee Count per Job Role")
plt.show()

plt.figure(figsize=(6,4))
sns.histplot(df['age'], bins=10, kde=True)
plt.title("Age Distribution")
plt.show()

plt.figure(figsize=(6,4))
sns.histplot(df['salary'], bins=10, kde=True)
plt.title("Salary Distribution")
plt.show()

plt.figure(figsize=(6,4))
sns.histplot(df['years_at_company'], bins=10, kde=True)
plt.title("Years at Company Distribution")
plt.show()

from transformers import pipeline

# Load sentiment + emotion model (multilabel)
emotion_pipe = pipeline("text-classification",
                        model="j-hartmann/emotion-english-distilroberta-base",
                        return_all_scores=True)

def extract_top_emotions(text, top_k=2):
    preds = emotion_pipe(text[:512])[0]  # truncate long text
    sorted_preds = sorted(preds, key=lambda x: x['score'], reverse=True)
    return [(p['label'], round(p['score'], 3)) for p in sorted_preds[:top_k]]

df['top_emotions'] = df['employee_text'].apply(extract_top_emotions)
df[['employee_text', 'top_emotions']].head()





from sentence_transformers import SentenceTransformer

encoder = SentenceTransformer('all-MiniLM-L6-v2')  # or use 'paraphrase-multilingual-MiniLM-L12-v2' for French/Arabic
df['embedding'] = encoder.encode(df['employee_text'].tolist()).tolist()

def flag_risk(emotions):
    risky_labels = ["disappointment", "anger", "resentment", "sadness", "nervousness"]
    return any(label in dict(emotions) for label in risky_labels)

df['risk_flag'] = df['top_emotions'].apply(flag_risk)

at_risk = df[df['risk_flag']]
at_risk[['department', 'job_role', 'employee_text', 'top_emotions']]

from collections import Counter

# Flatten and count emotion labels
all_emotions = [label for emo in df['top_emotions'] for label, _ in emo]
emo_counts = Counter(all_emotions)

plt.figure(figsize=(10,5))
plt.bar(emo_counts.keys(), emo_counts.values())
plt.title("Most Frequent Emotions in Employee Feedback")
plt.xticks(rotation=45)
plt.show()

plt.figure(figsize=(10,5))
sns.countplot(data=df, x='department', hue='risk_flag', palette={True: 'red', False: 'green'})
plt.title("At-Risk vs Safe Employees by Department")
plt.ylabel("Number of Employees")
plt.legend(title='At Risk?')
plt.grid(True, axis='y', linestyle='--', alpha=0.6)
plt.show()

risk_counts = df['risk_flag'].value_counts()
plt.figure(figsize=(6,6))
plt.pie(risk_counts, labels=['Not at Risk', 'At Risk'], autopct='%1.1f%%', colors=['green', 'red'])
plt.title("Employee Risk Distribution")
plt.show()

from wordcloud import WordCloud

risky_text = " ".join(df[df['risk_flag']]['employee_text'])
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(risky_text)

plt.figure(figsize=(10,5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title("Word Cloud of High-Risk Feedback")
plt.show()

from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-MiniLM-L6-v2')  # Small, powerful, fast
embeddings = model.encode(df['employee_text'].tolist(), show_progress_bar=True)

from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=4, random_state=42)
df['cluster'] = kmeans.fit_predict(embeddings)

import umap.umap_ as umap
reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)
embedding_2d = reducer.fit_transform(embeddings)

plt.figure(figsize=(10,6))
scatter = plt.scatter(embedding_2d[:,0], embedding_2d[:,1], c=df['cluster'], cmap='tab10', s=60)
plt.title("Employee Feedback Clusters (UMAP Projection)")
plt.colorbar(scatter, label='Cluster')
plt.grid(True)
plt.show()

for cluster_id in sorted(df['cluster'].unique()):
    print(f"\nðŸ”¹ Cluster {cluster_id} â€” Sample Feedbacks:")
    print(df[df['cluster'] == cluster_id]['employee_text'].sample(3, random_state=42).to_string(index=False))

cluster_stats = df.groupby('cluster').agg({
    'risk_flag': 'mean',
    'department': pd.Series.nunique,
    'top_emotions': lambda x: Counter([label for row in x for label, _ in row]).most_common(3)
})

cluster_stats['%_at_risk'] = (cluster_stats['risk_flag'] * 100).round(1)
cluster_stats.drop(columns='risk_flag')

